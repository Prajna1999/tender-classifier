{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic\n",
    "%pip install pandas\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mistralai\n",
      "  Downloading mistralai-1.5.0-py3-none-any.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jsonpath-python>=1.0.6\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Collecting eval-type-backport>=0.2.0\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting typing-inspect>=0.9.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: pydantic>=2.9.0 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from mistralai) (2.10.6)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from mistralai) (0.28.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from mistralai) (2.9.0.post0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from httpx>=0.27.0->mistralai) (1.0.7)\n",
      "Requirement already satisfied: certifi in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from httpx>=0.27.0->mistralai) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from httpx>=0.27.0->mistralai) (4.8.0)\n",
      "Requirement already satisfied: idna in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from httpx>=0.27.0->mistralai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->mistralai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from pydantic>=2.9.0->mistralai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from pydantic>=2.9.0->mistralai) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from pydantic>=2.9.0->mistralai) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->mistralai) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->mistralai) (1.2.2)\n",
      "Installing collected packages: mypy-extensions, jsonpath-python, eval-type-backport, typing-inspect, mistralai\n",
      "Successfully installed eval-type-backport-0.2.2 jsonpath-python-1.0.6 mistralai-1.5.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "MISTRAL_API_KEY=os.getenv('MISTRAL_API_KEY')\n",
    "DEFAULT_MISTRAL_MODEL=os.getenv('DEFAULT_MISTRAL_MODEL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mistralai.sdk.Mistral object at 0x7f3a04abd660>\n"
     ]
    }
   ],
   "source": [
    "from mistralai import Mistral\n",
    "client=Mistral(api_key=MISTRAL_API_KEY)\n",
    "print(client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_prompt(tender_contents):\n",
    "    \"\"\"\n",
    "    Builds an improved classification prompt for flood/non-flood tender classification\n",
    "    \"\"\"\n",
    "    return f'''You are a specialized tender classification system for identifying flood-related infrastructure and development projects. Your task is to analyze tender details and determine whether they are flood-related or non-flood-related, providing clear reasoning for your classification.\n",
    "\n",
    "INPUT TENDER:\n",
    "<tender>{tender_contents}</tender>\n",
    "\n",
    "CLASSIFICATION GUIDELINES:\n",
    "\n",
    "1. Primary Indicators (High confidence markers):\n",
    "- Direct flood protection/prevention works\n",
    "- Flood damage restoration\n",
    "- Flood-related infrastructure (embankments, dykes, etc.)\n",
    "- Emergency response facilities for floods\n",
    "- Drainage systems in flood-prone areas\n",
    "\n",
    "2. Secondary Indicators (Context-dependent):\n",
    "- Water management projects\n",
    "- Infrastructure reinforcement in flood zones\n",
    "- Road/bridge repairs mentioning rain/water damage\n",
    "- Erosion control measures\n",
    "- Watershed management\n",
    "\n",
    "3. Temporal Factors to Consider:\n",
    "- Pre-monsoon preparation works\n",
    "- Post-flood restoration\n",
    "- Seasonal timing of the tender\n",
    "- Emergency vs. planned works\n",
    "\n",
    "4. Key Terms Analysis:\n",
    "Positive indicators:\n",
    "- Flood protection/control\n",
    "- Embankment/dyke construction\n",
    "- Storm water management\n",
    "- Erosion control\n",
    "- Drainage systems\n",
    "- SDRF (State Disaster Response Fund) projects\n",
    "- Inundation prevention\n",
    "\n",
    "Negative indicators (likely non-flood):\n",
    "- Regular construction\n",
    "- Routine maintenance\n",
    "- Unrelated infrastructure (unless specifically flood-protection)\n",
    "- General development works\n",
    "- Standard civic amenities\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "\n",
    "1. First, analyze the tender details and provide your reasoning within <reasoning> tags. Consider:\n",
    "   - Primary purpose of the work\n",
    "   - Presence of flood-related keywords and context\n",
    "   - Temporal factors (season, urgency)\n",
    "   - Geographic relevance\n",
    "   - Project scale and scope\n",
    "   - Department/agency involved\n",
    "   - Any ambiguity in classification\n",
    "\n",
    "2. Then, output EXACTLY ONE classification label within <intent> tags:\n",
    "   <intents>\n",
    "   <intent>Flood</intent>\n",
    "   <intent>Non-Flood</intent>\n",
    "   <intent>Ambiguous </intent>\n",
    "   </intents>\n",
    "\n",
    "3. In case of ambiguity:\n",
    "   - Prioritize flood classification if there's clear flood-prevention/mitigation aspect\n",
    "   - Default to non-flood if flood relation is peripheral or unclear\n",
    "   - Document uncertainty in reasoning\n",
    "\n",
    "Example Classifications:\n",
    "\n",
    "1. Clear Flood Case:\n",
    "<reasoning>\n",
    "Tender explicitly mentions flood protection works, includes embankment construction, \n",
    "and is scheduled pre-monsoon. Department is water resources, indicating flood management focus.\n",
    "</reasoning>\n",
    "<intent>Flood</intent>\n",
    "\n",
    "2. Ambiguous Case:\n",
    "<reasoning>\n",
    "While tender includes drainage works, it appears to be part of routine road construction \n",
    "rather than specific flood management. No explicit flood prevention purpose mentioned.\n",
    "</reasoning>\n",
    "<intent>Ambiguous</intent>\n",
    "\n",
    "3. Clear Non-Flood Case:\n",
    "<reasoning>\n",
    "Standard building construction tender for government office. \n",
    "No flood-related components or considerations mentioned.\n",
    "</reasoning>\n",
    "<intent>Non-Flood</intent>\n",
    "\n",
    "YOUR CLASSIFICATION:\n",
    "Please analyze the provided tender and provide your classification following the above format. Make the reasoning succint and to the point to consume less output token.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a classifiy tender function with reasoning, intent and evaluation\n",
    "import re\n",
    "def classify_tenders(tender_contents):\n",
    "    classification_prompt=build_classification_prompt(tender_contents)\n",
    "    message=client.chat.complete(\n",
    "        model=DEFAULT_MISTRAL_MODEL,\n",
    "        max_tokens=512,\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n",
    "        stream=False\n",
    "    )\n",
    "    # get usage statistics\n",
    "    # usage=message.usage\n",
    "    # extract the reasoning and the content\n",
    "    reasoning_and_intent=message.choices[0].message.content\n",
    "    reasoning_match=re.search(\n",
    "              r\"<reasoning>(.*?)</reasoning>\", reasoning_and_intent, re.DOTALL\n",
    "    )\n",
    "    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "\n",
    "    # Similarly, also extract the `intent`.\n",
    "    intent_match = re.search(r\"<intent>(.*?)</intent>\", reasoning_and_intent, re.DOTALL)\n",
    "    intent = intent_match.group(1).strip() if intent_match else \"\"\n",
    "\n",
    "    return reasoning, intent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def process_csv_tenders(\n",
    "        csv_path: str,\n",
    "        output_path: str,\n",
    "        batch_size: int = 10,\n",
    "        max_retries: int = 1,\n",
    "        delay_between_batches: float = 1.0):\n",
    "    \"\"\"\n",
    "    Process a CSV file of tenders and classify each tender using the classify_tenders function.\n",
    "    Writes results to CSV after each batch.\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to the CSV file containing tenders\n",
    "        output_path: Path where to save the output CSV\n",
    "        batch_size: Number of tenders to process in parallel\n",
    "        max_retries: Maximum number of retries for failed classifications\n",
    "        delay_between_batches: Delay in seconds between processing batches\n",
    "    \"\"\"\n",
    "    # Set up logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        filename='tender_classification.log'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        logging.info(f\"Successfully loaded CSV file with {len(df)} rows\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading CSV file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    # Create result columns\n",
    "    df['classification_reasoning'] = ''\n",
    "    df['classification_intent'] = ''\n",
    "    df['classification_status'] = 'pending'\n",
    "    df['classification_error'] = ''\n",
    "\n",
    "    # Initialize output CSV with headers\n",
    "    df.head(0).to_csv(output_path, index=False)\n",
    "    processed_count = 0\n",
    "    successful_count = 0\n",
    "    failed_count = 0\n",
    "\n",
    "    def process_single_tender(row_idx: int) -> Dict:\n",
    "        \"\"\"Process a single tender with retries\"\"\"\n",
    "        row = df.iloc[row_idx]\n",
    "\n",
    "        tender_contents = {\n",
    "            'tender_id': row.get('Tender ID', ''),\n",
    "            'title': row.get('tender_title', ''),\n",
    "            'description': row.get('Work Description', ''),\n",
    "            'department': row.get('Department', ''),\n",
    "            'season': row.get('Season', ''),\n",
    "            'keywords': row.get('positive_keywords_dict', {})\n",
    "        }\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # 3 second delay to screw the API rate limit of Mistral\n",
    "                time.sleep(5)\n",
    "                reasoning, intent = classify_tenders(tender_contents)\n",
    "                return {\n",
    "                    'idx': row_idx,\n",
    "                    'reasoning': reasoning,\n",
    "                    'intent': intent,\n",
    "                    'status': 'success',\n",
    "                    'error': ''\n",
    "                }\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    error_msg = f\"Failed after {max_retries} attempts: {str(e)}\"\n",
    "                    logging.error(f\"Tender {row_idx} - {error_msg}\")\n",
    "                    return {\n",
    "                        'idx': row_idx,\n",
    "                        'reasoning': '',\n",
    "                        'intent': '',\n",
    "                        'status': 'failed',\n",
    "                        'error': error_msg\n",
    "                    }\n",
    "                time.sleep(2)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "        for batch_start in tqdm(range(0, len(df), batch_size)):\n",
    "            batch_end = min(batch_start + batch_size, len(df))\n",
    "            batch_indices = range(batch_start, batch_end)\n",
    "            \n",
    "            # Process batch\n",
    "            futures = [executor.submit(process_single_tender, idx) for idx in batch_indices]\n",
    "            results = [future.result() for future in futures]\n",
    "            \n",
    "            # Update DataFrame with results for this batch\n",
    "            batch_df = df.iloc[batch_start:batch_end].copy()\n",
    "            for result in results:\n",
    "                idx = result['idx'] - batch_start  # Relative index in batch\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_reasoning')] = result['reasoning']\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_intent')] = result['intent']\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_status')] = result['status']\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_error')] = result['error']\n",
    "            \n",
    "            # Append batch results to output CSV\n",
    "            batch_df.to_csv(output_path, mode='a', header=False, index=False)\n",
    "            \n",
    "            # Update statistics\n",
    "            successful = sum(1 for r in results if r['status'] == 'success')\n",
    "            successful_count += successful\n",
    "            failed_count += len(results) - successful\n",
    "            processed_count += len(results)\n",
    "            \n",
    "            # Log batch progress\n",
    "            logging.info(f\"Batch {batch_start//batch_size + 1}: {successful}/{len(results)} successful\")\n",
    "            logging.info(f\"Progress: {processed_count}/{len(df)} tenders processed\")\n",
    "            \n",
    "            # Delay between batches\n",
    "            if batch_end < len(df):\n",
    "                time.sleep(delay_between_batches)\n",
    "    \n",
    "    # Log final summary\n",
    "    logging.info(f\"\"\"\n",
    "    Classification Summary:\n",
    "    Total Processed: {processed_count}\n",
    "    Successful: {successful_count}\n",
    "    Failed: {failed_count}\n",
    "    Output saved to: {output_path}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/96 [00:33<12:41,  8.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m MAX_RETRIES\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Process the tenders\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     results_csv \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_csv_tenders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_RETRIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelay_between_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDELAY\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification completed successfully. Results saved to classified_tenders.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 123\u001b[0m, in \u001b[0;36mprocess_csv_tenders\u001b[0;34m(csv_path, output_path, batch_size, max_retries, delay_between_batches)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m# Delay between batches\u001b[39;00m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m batch_end \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(df):\n\u001b[0;32m--> 123\u001b[0m             \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay_between_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Log final summary\u001b[39;00m\n\u001b[1;32m    126\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124mClassification Summary:\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124mTotal Processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessed_count\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124mOutput saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configure parameters\n",
    "    CSV_PATH = \"/home/prajna/civicdatalab/himachal/tender-classifier/data/assam/raw_tenders/2024_03_tenders.csv\"\n",
    "    OUTPUT_PATH=\"/home/prajna/civicdatalab/himachal/tender-classifier/data/assam/classified_tenders_mistral/2024_03_classified_tenders.csv\"\n",
    "    BATCH_SIZE = 6 # Adjust based on API rate limits\n",
    "    DELAY = 2.0  # Seconds between batches\n",
    "    MAX_RETRIES=3\n",
    "    \n",
    "    try:\n",
    "        # Process the tenders\n",
    "        results_csv = process_csv_tenders(\n",
    "            csv_path=CSV_PATH,\n",
    "            output_path=OUTPUT_PATH,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            max_retries=MAX_RETRIES,\n",
    "            delay_between_batches=DELAY\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        print(\"Classification completed successfully. Results saved to classified_tenders.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tenders: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tender-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
