{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic\n",
    "%pip install pandas\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY=os.getenv('ANTHROPIC_API_KEY')\n",
    "DEFAULT_MODEL=os.getenv('DEFAULT_MODEL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "client=anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_prompt(tender_contents):\n",
    "    \"\"\"\n",
    "    Builds an improved classification prompt for flood/non-flood tender classification\n",
    "    \"\"\"\n",
    "    return f'''You are a specialized tender classification system for identifying flood-related infrastructure and development projects. Your task is to analyze tender details and determine whether they are flood-related or non-flood-related, providing clear reasoning for your classification.\n",
    "\n",
    "INPUT TENDER:\n",
    "<tender>{tender_contents}</tender>\n",
    "\n",
    "CLASSIFICATION GUIDELINES:\n",
    "\n",
    "1. Primary Indicators (High confidence markers):\n",
    "- Direct flood protection/prevention works\n",
    "- Flood damage restoration\n",
    "- Flood-related infrastructure (embankments, dykes, etc.)\n",
    "- Emergency response facilities for floods\n",
    "- Drainage systems in flood-prone areas\n",
    "\n",
    "2. Secondary Indicators (Context-dependent):\n",
    "- Water management projects\n",
    "- Infrastructure reinforcement in flood zones\n",
    "- Road/bridge repairs mentioning rain/water damage\n",
    "- Erosion control measures\n",
    "- Watershed management\n",
    "\n",
    "3. Temporal Factors to Consider:\n",
    "- Pre-monsoon preparation works\n",
    "- Post-flood restoration\n",
    "- Seasonal timing of the tender\n",
    "- Emergency vs. planned works\n",
    "\n",
    "4. Key Terms Analysis:\n",
    "Positive indicators:\n",
    "- Flood protection/control\n",
    "- Embankment/dyke construction\n",
    "- Storm water management\n",
    "- Erosion control\n",
    "- Drainage systems\n",
    "- SDRF (State Disaster Response Fund) projects\n",
    "- Inundation prevention\n",
    "\n",
    "Negative indicators (likely non-flood):\n",
    "- Regular construction\n",
    "- Routine maintenance\n",
    "- Unrelated infrastructure (unless specifically flood-protection)\n",
    "- General development works\n",
    "- Standard civic amenities\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "\n",
    "1. First, analyze the tender details and provide your reasoning within <reasoning> tags. Consider:\n",
    "   - Primary purpose of the work\n",
    "   - Presence of flood-related keywords and context\n",
    "   - Temporal factors (season, urgency)\n",
    "   - Geographic relevance\n",
    "   - Project scale and scope\n",
    "   - Department/agency involved\n",
    "   - Any ambiguity in classification\n",
    "\n",
    "2. Then, output EXACTLY ONE classification label within <intent> tags:\n",
    "   <intents>\n",
    "   <intent>Flood</intent>\n",
    "   <intent>Non-Flood</intent>\n",
    "   <intent>Ambiguous </intent>\n",
    "   </intents>\n",
    "\n",
    "3. In case of ambiguity:\n",
    "   - Prioritize flood classification if there's clear flood-prevention/mitigation aspect\n",
    "   - Default to non-flood if flood relation is peripheral or unclear\n",
    "   - Document uncertainty in reasoning\n",
    "\n",
    "Example Classifications:\n",
    "\n",
    "1. Clear Flood Case:\n",
    "<reasoning>\n",
    "Tender explicitly mentions flood protection works, includes embankment construction, \n",
    "and is scheduled pre-monsoon. Department is water resources, indicating flood management focus.\n",
    "</reasoning>\n",
    "<intent>Flood</intent>\n",
    "\n",
    "2. Ambiguous Case:\n",
    "<reasoning>\n",
    "While tender includes drainage works, it appears to be part of routine road construction \n",
    "rather than specific flood management. No explicit flood prevention purpose mentioned.\n",
    "</reasoning>\n",
    "<intent>Ambiguous</intent>\n",
    "\n",
    "3. Clear Non-Flood Case:\n",
    "<reasoning>\n",
    "Standard building construction tender for government office. \n",
    "No flood-related components or considerations mentioned.\n",
    "</reasoning>\n",
    "<intent>Non-Flood</intent>\n",
    "\n",
    "YOUR CLASSIFICATION:\n",
    "Please analyze the provided tender and provide your classification following the above format.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a classifiy tender function with reasoning, intent and evaluation\n",
    "import re\n",
    "def classify_tenders(tender_contents):\n",
    "    classification_prompt=build_classification_prompt(tender_contents)\n",
    "    message=client.messages.create(\n",
    "        model=DEFAULT_MODEL,\n",
    "        max_tokens=512,\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n",
    "        stream=False\n",
    "    )\n",
    "    # get usage statistics\n",
    "    # usage=message.usage\n",
    "    # extract the reasoning and the content\n",
    "    reasoning_and_intent=message.content[0].text\n",
    "    reasoning_match=re.search(\n",
    "              r\"<reasoning>(.*?)</reasoning>\", reasoning_and_intent, re.DOTALL\n",
    "    )\n",
    "    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "\n",
    "    # Similarly, also extract the `intent`.\n",
    "    intent_match = re.search(r\"<intent>(.*?)</intent>\", reasoning_and_intent, re.DOTALL)\n",
    "    intent = intent_match.group(1).strip() if intent_match else \"\"\n",
    "\n",
    "    return reasoning, intent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/prajna/civicdatalab/himachal/tender-classifier/tender-classifier/lib/python3.10/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def process_csv_tenders(\n",
    "        csv_path: str,\n",
    "        output_path: str,\n",
    "        batch_size: int = 10,\n",
    "        max_retries: int = 1,\n",
    "        delay_between_batches: float = 1.0):\n",
    "    \"\"\"\n",
    "    Process a CSV file of tenders and classify each tender using the classify_tenders function.\n",
    "    Writes results to CSV after each batch.\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to the CSV file containing tenders\n",
    "        output_path: Path where to save the output CSV\n",
    "        batch_size: Number of tenders to process in parallel\n",
    "        max_retries: Maximum number of retries for failed classifications\n",
    "        delay_between_batches: Delay in seconds between processing batches\n",
    "    \"\"\"\n",
    "    # Set up logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        filename='tender_classification.log'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        logging.info(f\"Successfully loaded CSV file with {len(df)} rows\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading CSV file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    # Create result columns\n",
    "    df['classification_reasoning'] = ''\n",
    "    df['classification_intent'] = ''\n",
    "    df['classification_status'] = 'pending'\n",
    "    df['classification_error'] = ''\n",
    "\n",
    "    # Initialize output CSV with headers\n",
    "    df.head(0).to_csv(output_path, index=False)\n",
    "    processed_count = 0\n",
    "    successful_count = 0\n",
    "    failed_count = 0\n",
    "\n",
    "    def process_single_tender(row_idx: int) -> Dict:\n",
    "        \"\"\"Process a single tender with retries\"\"\"\n",
    "        row = df.iloc[row_idx]\n",
    "\n",
    "        tender_contents = {\n",
    "            'tender_id': row.get('Tender ID', ''),\n",
    "            'title': row.get('tender_title', ''),\n",
    "            'description': row.get('Work Description', ''),\n",
    "            'department': row.get('Department', ''),\n",
    "            'season': row.get('Season', ''),\n",
    "            'keywords': row.get('positive_keywords_dict', {})\n",
    "        }\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                reasoning, intent = classify_tenders(tender_contents)\n",
    "                return {\n",
    "                    'idx': row_idx,\n",
    "                    'reasoning': reasoning,\n",
    "                    'intent': intent,\n",
    "                    'status': 'success',\n",
    "                    'error': ''\n",
    "                }\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    error_msg = f\"Failed after {max_retries} attempts: {str(e)}\"\n",
    "                    logging.error(f\"Tender {row_idx} - {error_msg}\")\n",
    "                    return {\n",
    "                        'idx': row_idx,\n",
    "                        'reasoning': '',\n",
    "                        'intent': '',\n",
    "                        'status': 'failed',\n",
    "                        'error': error_msg\n",
    "                    }\n",
    "                time.sleep(1)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "        for batch_start in tqdm(range(0, len(df), batch_size)):\n",
    "            batch_end = min(batch_start + batch_size, len(df))\n",
    "            batch_indices = range(batch_start, batch_end)\n",
    "            \n",
    "            # Process batch\n",
    "            futures = [executor.submit(process_single_tender, idx) for idx in batch_indices]\n",
    "            results = [future.result() for future in futures]\n",
    "            \n",
    "            # Update DataFrame with results for this batch\n",
    "            batch_df = df.iloc[batch_start:batch_end].copy()\n",
    "            for result in results:\n",
    "                idx = result['idx'] - batch_start  # Relative index in batch\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_reasoning')] = result['reasoning']\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_intent')] = result['intent']\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_status')] = result['status']\n",
    "                batch_df.iloc[idx, batch_df.columns.get_loc('classification_error')] = result['error']\n",
    "            \n",
    "            # Append batch results to output CSV\n",
    "            batch_df.to_csv(output_path, mode='a', header=False, index=False)\n",
    "            \n",
    "            # Update statistics\n",
    "            successful = sum(1 for r in results if r['status'] == 'success')\n",
    "            successful_count += successful\n",
    "            failed_count += len(results) - successful\n",
    "            processed_count += len(results)\n",
    "            \n",
    "            # Log batch progress\n",
    "            logging.info(f\"Batch {batch_start//batch_size + 1}: {successful}/{len(results)} successful\")\n",
    "            logging.info(f\"Progress: {processed_count}/{len(df)} tenders processed\")\n",
    "            \n",
    "            # Delay between batches\n",
    "            if batch_end < len(df):\n",
    "                time.sleep(delay_between_batches)\n",
    "    \n",
    "    # Log final summary\n",
    "    logging.info(f\"\"\"\n",
    "    Classification Summary:\n",
    "    Total Processed: {processed_count}\n",
    "    Successful: {successful_count}\n",
    "    Failed: {failed_count}\n",
    "    Output saved to: {output_path}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [23:29<00:00, 23.89s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed successfully. Results saved to classified_tenders.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configure parameters\n",
    "    CSV_PATH = \"/home/prajna/civicdatalab/himachal/tender-classifier/data/test_data/2022_08_tenders_100.csv\"\n",
    "    OUTPUT_PATH=\"/home/prajna/civicdatalab/himachal/tender-classifier/data/test_data/2022_08_classified_tenders_100.csv\"\n",
    "    BATCH_SIZE = 7  # Adjust based on API rate limits\n",
    "    DELAY = 1.0  # Seconds between batches\n",
    "    \n",
    "    try:\n",
    "        # Process the tenders\n",
    "        results_csv = process_csv_tenders(\n",
    "            csv_path=CSV_PATH,\n",
    "            output_path=OUTPUT_PATH,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            delay_between_batches=DELAY\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        # results_df.to_csv(\"/home/prajna/civicdatalab/himachal/tender-classifier/data/test_data/classified_tenders.csv\", index=False)\n",
    "        print(\"Classification completed successfully. Results saved to classified_tenders.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tenders: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tender-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
